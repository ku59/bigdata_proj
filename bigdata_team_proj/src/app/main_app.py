import os
import sys
import streamlit as st
import datetime as dt
import json

# Ensure project root on sys.path for absolute imports like 'src.*'
PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
if PROJECT_ROOT not in sys.path:
    sys.path.insert(0, PROJECT_ROOT)

from src.agent.workflow_graph import build_workflow
from src.agent.tools import (
    tool_get_latest_finstat,
    tool_get_finstat_bulk,
    tool_search_news,
)
from src.app.components import (
    render_agent_answer,
    render_financial_cards,
    render_financial_trend,
    render_news_cards,
)
from src.utils.logging_utils import configure_logging
from src.agent.prompts import SYSTEM_PROMPT
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, SystemMessage
from src.utils.settings import settings


def _compute_briefing_year(mode_label: str, years: list[str], selected_brief_year: str | None) -> tuple[str, str | None]:
    if mode_label == "ìµœì‹ ":
        briefing_year_mode = "latest"
        briefing_year = None
        if years:
            try:
                briefing_year = max(years, key=lambda y: int(y))
            except Exception:
                briefing_year = years[-1]
    else:
        briefing_year_mode = "selected"
        briefing_year = selected_brief_year
    return briefing_year_mode, briefing_year


def _split_company_code(raw: str | None) -> tuple[str | None, str | None]:
    """
    ì…ë ¥ ë¬¸ìì—´ì—ì„œ ê³µì‹œ ê³ ìœ ì½”ë“œ(8ìë¦¬) ë˜ëŠ” ì£¼ì‹ ì½”ë“œ(6ìë¦¬)ë¥¼ êµ¬ë¶„í•˜ì—¬ ë°˜í™˜.
    - ë°˜í™˜: (corp_code, stock_code)
    """
    if not raw:
        return None, None
    s = raw.strip()
    if len(s) == 8:
        return s, None
    if len(s) == 6:
        return None, s
    return None, None


def _persist_analysis(params: dict, result: dict) -> None:
    st.session_state["analysis"] = {
        **params,
        "result": result,
    }


def _render_tabs(analysis: dict) -> None:
    company_name = analysis.get("company_name")
    corp_code = analysis.get("corp_code")
    question = analysis.get("question")
    years = analysis.get("years", [])
    reprt_codes = analysis.get("reprt_codes", [])
    fs_div = analysis.get("fs_div")
    news_sort = analysis.get("news_sort")
    news_limit = analysis.get("news_limit")
    dedup_strength = analysis.get("dedup_strength")
    sort_label = analysis.get("sort_label")
    dedup_label = analysis.get("dedup_label")
    briefing_year = analysis.get("briefing_year")
    briefing_year_mode = analysis.get("briefing_year_mode")
    result = analysis.get("result", {})
    
    # âœ… workflowì—ì„œ ê°€ì ¸ì˜¨ ë°ì´í„° ì¶”ì¶œ
    news_from_workflow = result.get("news_items", [])
    financial_from_workflow = result.get("financial")
    retrieved_docs = result.get("retrieved_docs", [])

    # âœ… ë””ë²„ê·¸ ì •ë³´
    st.sidebar.markdown("### ğŸ” ë””ë²„ê·¸ ì •ë³´")
    st.sidebar.write(f"Retrieved Docs: {len(retrieved_docs)}ê±´")
    st.sidebar.write(f"News Items: {len(news_from_workflow)}ê±´")
    st.sidebar.write(f"Financial Data: {'ìˆìŒ' if financial_from_workflow else 'ì—†ìŒ'}")
    st.sidebar.write(f"Answer: {'ìˆìŒ' if result.get('answer') else 'ì—†ìŒ'}")

    # âœ… RAG ì†ŒìŠ¤ íƒ­ ì¶”ê°€
    tab_overview, tab_news, tab_fin, tab_briefing, tab_rag_source, tab_chat = st.tabs(
        ["ê°œìš”", "ë‰´ìŠ¤", "ê³µì‹œ/ì¬ë¬´", "AI ë¸Œë¦¬í•‘", "RAG ì†ŒìŠ¤", "ëŒ€í™”"]
    )

    with tab_overview:
        st.subheader("ê°œìš”")
        st.write("ì…ë ¥ëœ íŒŒë¼ë¯¸í„°")
        st.json(
            {
                "íšŒì‚¬ëª…": company_name,
                "ê³µì‹œ ê³ ìœ ì½”ë“œ": corp_code,
                "ë¸Œë¦¬í•‘ ê¸°ì¤€": {"ëª¨ë“œ": briefing_year_mode, "ì—°ë„": briefing_year},
                "ë‰´ìŠ¤": {"í‘œì‹œ ìˆ˜": news_limit, "ì •ë ¬": sort_label, "ì¤‘ë³µ ê°•ë„": dedup_label},
                "ì¬ë¬´": {"ì—°ë„": years, "ë³´ê³ ì„œ ì½”ë“œ": reprt_codes, "ê¸°ì¤€": fs_div},
            }
        )
        
        # ë””ë²„ê·¸: workflow result ì „ì²´ êµ¬ì¡° í™•ì¸
        with st.expander("ğŸ› ë””ë²„ê·¸: Workflow Result ì „ì²´ êµ¬ì¡°"):
            st.json({
                "keys": list(result.keys()),
                "retrieved_docs_count": len(result.get("retrieved_docs", [])),
                "news_items_count": len(result.get("news_items", [])),
                "has_financial": result.get("financial") is not None,
                "has_answer": result.get("answer") is not None,
                "route": result.get("route"),
            })

    with tab_fin:
        st.subheader("ì¬ë¬´ì§€í‘œ")
        if corp_code:
            # âœ… workflow ê²°ê³¼ê°€ ìˆìœ¼ë©´ ë¨¼ì € ì‚¬ìš©
            if financial_from_workflow and briefing_year:
                st.caption(f"ë¸Œë¦¬í•‘ ê¸°ì¤€ ì—°ë„: {briefing_year}")
                metrics_keys = ["assets", "liabilities", "equity", "revenue", "operating_income", "net_income"]
                if any(financial_from_workflow.get(k) is not None for k in metrics_keys):
                    render_financial_cards(financial_from_workflow)
                else:
                    st.warning("ë¸Œë¦¬í•‘ ì—°ë„ ê¸°ì¤€ ì¬ë¬´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                # ê¸°ì¡´ ë¡œì§ ìœ ì§€ (ì‚¬ìš©ìê°€ íƒ­ì—ì„œ ì§ì ‘ ì¡°íšŒí•˜ëŠ” ê²½ìš°)
                if len(years) == 1 and len(reprt_codes) == 1:
                    fin = tool_get_latest_finstat(
                        corp_code=corp_code,
                        year=years[0],
                        reprt_code=reprt_codes[0],
                        fs_div=fs_div,
                    )
                    metrics_keys = ["assets", "liabilities", "equity", "revenue", "operating_income", "net_income"]
                    if any(fin.get(k) is not None for k in metrics_keys):
                        render_financial_cards(fin)
                    else:
                        st.warning("í•´ë‹¹ ì—°ë„/ë³´ê³ ì„œ ì¡°í•©ìœ¼ë¡œ ì¡°íšŒëœ ì¬ë¬´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì…ë ¥ê°’ì„ í™•ì¸í•˜ì„¸ìš”.")
                else:
                    fin_items = tool_get_finstat_bulk(
                        corp_code=corp_code,
                        years=years,
                        reprt_codes=reprt_codes,
                        fs_div=fs_div,
                    )
                    if fin_items:
                        render_financial_trend(fin_items)
                    else:
                        st.warning("ì„ íƒí•œ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ì¬ë¬´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.info("ê³µì‹œ ê³ ìœ ì½”ë“œë¥¼ ì…ë ¥í•˜ë©´ ì¬ë¬´ ì§€í‘œê°€ í‘œì‹œë©ë‹ˆë‹¤. ì˜ˆ: ì‚¼ì„±ì „ì 00126380")

    with tab_news:
        st.subheader("ìµœê·¼ ë‰´ìŠ¤")
        if company_name:
            # âœ… workflow ê²°ê³¼ ì‚¬ìš© (API ì¬í˜¸ì¶œ X)
            if news_from_workflow:
                render_news_cards(news_items=news_from_workflow, original_count=None)
            else:
                st.warning("ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.info("íšŒì‚¬ëª…ì„ ì…ë ¥í•˜ë©´ ë‰´ìŠ¤ê°€ í‘œì‹œë©ë‹ˆë‹¤.")

    with tab_briefing:
        st.subheader("AI ë¸Œë¦¬í•‘")
        if briefing_year:
            st.caption(f"ë¸Œë¦¬í•‘ ê¸°ì¤€ ì—°ë„: {briefing_year}")
        render_agent_answer(result.get("answer", "ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."))

    # âœ… RAG ì†ŒìŠ¤ íƒ­ - 3ê°œ ì„¹ì…˜ìœ¼ë¡œ êµ¬ì„±
    with tab_rag_source:
        st.subheader("AI ë¸Œë¦¬í•‘ì— ì‚¬ìš©ëœ ë°ì´í„° ì†ŒìŠ¤")
        st.caption("AIê°€ ë‹µë³€ì„ ìƒì„±í•  ë•Œ ì°¸ê³ í•œ ëª¨ë“  ë°ì´í„°ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        # âœ… ë””ë²„ê·¸ ì •ë³´ ì¶”ê°€
        with st.expander("ğŸ› ë””ë²„ê·¸: ì›ë³¸ ë°ì´í„° êµ¬ì¡° í™•ì¸"):
            debug_info = {
                "result_keys": list(result.keys()),
                "retrieved_docs_type": str(type(retrieved_docs)),
                "retrieved_docs_length": len(retrieved_docs),
                "news_items_type": str(type(news_from_workflow)),
                "news_items_length": len(news_from_workflow),
                "financial_type": str(type(financial_from_workflow)),
                "financial_is_none": financial_from_workflow is None,
            }
            st.json(debug_info)
            
            if retrieved_docs:
                st.write("**ì²« ë²ˆì§¸ retrieved_doc ìƒ˜í”Œ:**")
                st.json(retrieved_docs[0])
            
            if news_from_workflow:
                st.write("**ì²« ë²ˆì§¸ news_item ìƒ˜í”Œ:**")
                st.json(news_from_workflow[0])
            
            if financial_from_workflow:
                st.write("**financial ë°ì´í„°:**")
                st.json(financial_from_workflow)
        
        # ì„¹ì…˜ 1: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê²°ê³¼ (Vector + Keyword)
        st.markdown("### ğŸ“š í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ë¬¸ì„œ (ES + Vector DB)")
        st.caption(f"ê²€ìƒ‰ëœ ë¬¸ì„œ: ì´ {len(retrieved_docs)}ê±´")
        
        if retrieved_docs:
            for idx, doc in enumerate(retrieved_docs, 1):
                with st.expander(f"ğŸ“„ ë¬¸ì„œ {idx} - {doc.get('metadata', {}).get('source', 'ì¶œì²˜ ì—†ìŒ')}"):
                    # ë©”íƒ€ë°ì´í„° ì •ë³´
                    meta = doc.get("metadata", {})
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("ì¶œì²˜", meta.get("source", "N/A"))
                    with col2:
                        st.metric("ì—°ë„", meta.get("year", "N/A"))
                    with col3:
                        hybrid_score = doc.get("hybrid_score", 0)
                        st.metric("ê´€ë ¨ë„ ì ìˆ˜", f"{hybrid_score:.4f}")
                    
                    # ìŠ¤ì½”ì–´ ìƒì„¸ ì •ë³´
                    st.caption("**ê²€ìƒ‰ ìŠ¤ì½”ì–´ ìƒì„¸**")
                    score_col1, score_col2, score_col3 = st.columns(3)
                    with score_col1:
                        st.write(f"ğŸ” í•˜ì´ë¸Œë¦¬ë“œ: `{doc.get('hybrid_score', 0):.4f}`")
                    with score_col2:
                        st.write(f"ğŸ“Š í‚¤ì›Œë“œ(Sparse): `{doc.get('sparse_score', 0):.4f}`")
                    with score_col3:
                        st.write(f"ğŸ§  ë²¡í„°(Dense): `{doc.get('dense_score', 0):.4f}`")
                    
                    # ë¬¸ì„œ ë‚´ìš©
                    st.markdown("**ë¬¸ì„œ ë‚´ìš©:**")
                    st.text_area(
                        "ë‚´ìš©",
                        value=doc.get("text", "ë‚´ìš© ì—†ìŒ"),
                        height=150,
                        key=f"doc_{idx}",
                        label_visibility="collapsed"
                    )
        else:
            st.info("ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. Elasticsearchë‚˜ Vector DBì— ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        
        st.divider()
        
        # ì„¹ì…˜ 2: DART API ì¬ë¬´ ë°ì´í„°
        st.markdown("### ğŸ’¼ DART API ì¬ë¬´ ë°ì´í„°")
        st.caption(f"ë¸Œë¦¬í•‘ ê¸°ì¤€ ì—°ë„: {briefing_year or 'N/A'}")
        
        if financial_from_workflow:
            with st.expander("ğŸ“Š ì¬ë¬´ì œí‘œ ìš”ì•½ (DART Open API)", expanded=True):
                st.json(financial_from_workflow)
                
                # ì£¼ìš” ì§€í‘œ ì‹œê°í™”
                metrics_keys = ["assets", "liabilities", "equity", "revenue", "operating_income", "net_income"]
                has_data = any(financial_from_workflow.get(k) is not None for k in metrics_keys)
                
                if has_data:
                    st.markdown("**ì£¼ìš” ì¬ë¬´ ì§€í‘œ:**")
                    m_col1, m_col2, m_col3 = st.columns(3)
                    with m_col1:
                        if financial_from_workflow.get("assets"):
                            st.metric("ì´ìì‚°", f"{financial_from_workflow['assets']:,}ë°±ë§Œì›")
                        if financial_from_workflow.get("revenue"):
                            st.metric("ë§¤ì¶œì•¡", f"{financial_from_workflow['revenue']:,}ë°±ë§Œì›")
                    with m_col2:
                        if financial_from_workflow.get("liabilities"):
                            st.metric("ë¶€ì±„", f"{financial_from_workflow['liabilities']:,}ë°±ë§Œì›")
                        if financial_from_workflow.get("operating_income"):
                            st.metric("ì˜ì—…ì´ìµ", f"{financial_from_workflow['operating_income']:,}ë°±ë§Œì›")
                    with m_col3:
                        if financial_from_workflow.get("equity"):
                            st.metric("ìë³¸", f"{financial_from_workflow['equity']:,}ë°±ë§Œì›")
                        if financial_from_workflow.get("net_income"):
                            st.metric("ìˆœì´ìµ", f"{financial_from_workflow['net_income']:,}ë°±ë§Œì›")
        else:
            st.info("DART ì¬ë¬´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê³µì‹œ ê³ ìœ ì½”ë“œì™€ ë¸Œë¦¬í•‘ ì—°ë„ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        
        st.divider()
        
        # ì„¹ì…˜ 3: Naver News API ê²°ê³¼
        st.markdown("### ğŸ“° Naver News API ê²°ê³¼")
        st.caption(f"ê²€ìƒ‰ëœ ë‰´ìŠ¤: ì´ {len(news_from_workflow)}ê±´")
        
        if news_from_workflow:
            for idx, news_item in enumerate(news_from_workflow, 1):
                title = news_item.get("title") or news_item.get("titlenorm") or "ì œëª© ì—†ìŒ"
                pub_date = news_item.get("pubDate") or "ë‚ ì§œ ì—†ìŒ"
                link = news_item.get("link") or news_item.get("originallink") or "#"
                desc = news_item.get("descriptionclean") or news_item.get("description") or "ë‚´ìš© ì—†ìŒ"
                
                with st.expander(f"ğŸ“° ë‰´ìŠ¤ {idx} - {title}"):
                    st.markdown(f"**ì œëª©:** {title}")
                    st.markdown(f"**ë°œí–‰ì¼:** {pub_date}")
                    st.markdown(f"**ë§í¬:** [{link}]({link})")
                    st.markdown(f"**ìš”ì•½:**")
                    st.write(desc)
                    
                    # ì¶”ê°€ ë©”íƒ€ë°ì´í„°ê°€ ìˆìœ¼ë©´ í‘œì‹œ
                    if news_item.get("similarity_score"):
                        st.caption(f"ìœ ì‚¬ë„ ì ìˆ˜: {news_item['similarity_score']:.4f}")
        else:
            st.info("ë„¤ì´ë²„ ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. íšŒì‚¬ëª…ì„ í™•ì¸í•˜ì„¸ìš”.")

    with tab_chat:
        st.subheader("ëŒ€í™”")
        if "chat_history" not in st.session_state:
            st.session_state["chat_history"] = []

        for msg in st.session_state["chat_history"]:
            st.chat_message(msg["role"]).write(msg["content"])

        user_msg = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”")
        if user_msg:
            st.session_state["chat_history"].append({"role": "user", "content": user_msg})

            # ìŠ¤íŠ¸ë¦¬ë° LLM ì´ˆê¸°í™”
            llm = ChatGoogleGenerativeAI(
                model=settings.GEMINI_MODEL_NAME,
                temperature=0.2,
                google_api_key=settings.GOOGLE_API_KEY,
            )

            # ë©”ì‹œì§€ êµ¬ì„±(ê°„ë‹¨í•œ ì»¨í…ìŠ¤íŠ¸ í¬í•¨)
            sys = SystemMessage(content=SYSTEM_PROMPT)
            context = f"íšŒì‚¬: {company_name or 'ë¯¸ì§€ì •'} / ê³µì‹œì½”ë“œ: {corp_code or 'ë¯¸ì§€ì •'} / ê¸°ì¤€ì—°ë„: {briefing_year or 'ë¯¸ì§€ì •'}"
            usr = HumanMessage(content=f"{context}\nì§ˆë¬¸: {user_msg}")

            assistant_box = st.chat_message("assistant")
            placeholder = assistant_box.empty()
            streamed = ""

            try:
                for chunk in llm.stream([sys, usr]):
                    text = getattr(chunk, "text", None) or getattr(chunk, "content", "")
                    if text:
                        streamed += text
                        placeholder.write(streamed)
                st.session_state["chat_history"].append({"role": "assistant", "content": streamed})
            except Exception:
                placeholder.write("ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")


def main() -> None:
    configure_logging()
    st.set_page_config(page_title="DART RAG Agent", layout="wide")
    st.title("ê¸°ì—… ë¶„ì„ Agentic RAG ë°ëª¨ (Gemini ê¸°ë°˜)")
    st.caption("íšŒì‚¬ëª…, ê³µì‹œ ê³ ìœ ì½”ë“œ, ë¶„ì„ ì§ˆë¬¸ì„ ì…ë ¥í•˜ê³  ì˜µì…˜ì„ ì„ íƒí•œ ë’¤ 'ë¶„ì„ ì‹¤í–‰'ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")

    # ì¤‘ì•™ í¼ UI (ê°„ì†Œí™” + í•œ í–‰ì— ì˜µì…˜ ë°°ì¹˜)
    years_opts = [str(y) for y in range(2019, 2026)]
    reprt_code_map = {
        "ì‚¬ì—…ë³´ê³ ì„œ (11011)": "11011",
        "ë°˜ê¸°ë³´ê³ ì„œ (11012)": "11012",
        "1ë¶„ê¸°ë³´ê³ ì„œ (11013)": "11013",
        "3ë¶„ê¸°ë³´ê³ ì„œ (11014)": "11014",
    }

    with st.form("input_form"):
        st.subheader("ê¸°ë³¸ ì •ë³´")
        col1, col2 = st.columns(2)
        with col1:
            company_name = st.text_input("íšŒì‚¬ëª…(ì˜ˆ: ì‚¼ì„±ì „ì)", placeholder="ì˜ˆ: ì‚¼ì„±ì „ì")
            corp_code = st.text_input("DART ê³µì‹œ ê³ ìœ ì½”ë“œ(ì˜ˆ : 00126380)", placeholder="ì˜ˆ: 00126380")
        with col2:
            question = st.text_area("ì§ˆë¬¸", value="ì´ íšŒì‚¬ì˜ ìµœê·¼ ì‹¤ì ê³¼ ë¦¬ìŠ¤í¬ë¥¼ ìš”ì•½í•´ì¤˜", height=120)

        st.divider()

        # í•œ í–‰ì— ë‰´ìŠ¤ ì˜µì…˜ê³¼ ê³µì‹œ/ì¬ë¬´ ì˜µì…˜ì„ ë°°ì¹˜
        opt_left, opt_right = st.columns(2)

        with opt_left:
            st.subheader("ë‰´ìŠ¤ ì˜µì…˜")
            sort_label = st.radio("ì •ë ¬", options=["ìœ ì‚¬ë„ìˆœ", "ë‚ ì§œìˆœ"], index=0, horizontal=True)
            dedup_label = st.radio("ì¤‘ë³µ ì œê±° ê°•ë„", options=["ì•½í•¨", "ë³´í†µ", "ê°•í•¨"], index=1, horizontal=True)
            news_limit = st.slider("ë‰´ìŠ¤ í‘œì‹œ ìˆ˜", min_value=5, max_value=50, value=10, step=5)

        with opt_right:
            st.subheader("ê³µì‹œ/ì¬ë¬´ ì˜µì…˜")
            years_mode = st.radio("ì¬ë¬´ ì—°ë„ ì„ íƒ", options=["ìµœê·¼ 1ë…„", "ìµœê·¼ 3ë…„", "ìµœê·¼ 5ë…„", "ìˆ˜ë™ ì„ íƒ"], index=1, horizontal=True)
            if years_mode == "ìˆ˜ë™ ì„ íƒ":
                years = st.multiselect("ì—°ë„ ì„ íƒ(ë³µìˆ˜ ì„ íƒ ê°€ëŠ¥)", options=years_opts, default=["2023"])
            else:
                current_year = dt.datetime.now().year
                if years_mode == "ìµœê·¼ 1ë…„":
                    chosen = [str(current_year)]
                elif years_mode == "ìµœê·¼ 3ë…„":
                    chosen = [str(y) for y in range(current_year - 2, current_year + 1)]
                else:  # ìµœê·¼ 5ë…„
                    chosen = [str(y) for y in range(current_year - 4, current_year + 1)]
                years = [y for y in chosen if y in years_opts]
            st.caption(f"ì„ íƒëœ ì—°ë„: {', '.join(years) if years else 'ì—†ìŒ'}")

            reprt_labels = st.multiselect(
                "ë³´ê³ ì„œ ì¢…ë¥˜",
                options=list(reprt_code_map.keys()),
                default=["ì‚¬ì—…ë³´ê³ ì„œ (11011)"],
            )
            reprt_codes = [reprt_code_map[l] for l in reprt_labels]

            fs_div_label = st.radio("ì¬ë¬´ì œí‘œ ê¸°ì¤€", options=["ì—°ê²°(CFS)", "ê°œë³„(OFS)"], index=0, horizontal=True)
            fs_div = "CFS" if fs_div_label.startswith("ì—°ê²°") else "OFS"

        st.divider()
        st.subheader("ë¸Œë¦¬í•‘ ê¸°ì¤€")
        briefing_mode_label = st.radio("ë¸Œë¦¬í•‘ ê¸°ì¤€ ì„ íƒ", options=["ìµœì‹ ", "ì„ íƒ"], index=0, horizontal=True)
        selected_brief_year = None
        if briefing_mode_label == "ì„ íƒ":
            selected_brief_year = st.selectbox("ë¸Œë¦¬í•‘ ì—°ë„", options=years_opts, index=len(years_opts) - 3)

        submitted = st.form_submit_button("ë¶„ì„ ì‹¤í–‰")

    # ê°’ ë§¤í•‘
    news_sort = "sim" if sort_label == "ìœ ì‚¬ë„ìˆœ" else "date"
    strength_map = {"ì•½í•¨": "low", "ë³´í†µ": "medium", "ê°•í•¨": "high"}
    dedup_strength = strength_map.get(dedup_label, "medium")

    # ë¸Œë¦¬í•‘ ì—°ë„ ê²°ì •
    briefing_year_mode, briefing_year = _compute_briefing_year(briefing_mode_label, years, selected_brief_year)

    # í¼ ì œì¶œ ì‹œ ë¶„ì„ ì‹¤í–‰ ë° ìƒíƒœ ì €ì¥
    if submitted and question:
        with st.spinner("ë¶„ì„ ì¤‘... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."):
            try:
                workflow = build_workflow()
                code_corp, code_stock = _split_company_code(corp_code)

                state = {
                    "question": question,
                    "company": company_name or None,
                    "corp_code": code_corp,
                    "stock_code": code_stock,
                    "retrieved_docs": [],
                    "answer": None,
                    "route": None,
                    "briefing_year": briefing_year,
                    "briefing_year_mode": briefing_year_mode,
                }

                result = workflow.invoke(state)
                
                # âœ… ë””ë²„ê·¸: workflow ì‹¤í–‰ ê²°ê³¼ í™•ì¸
                st.success(f"âœ… ë¶„ì„ ì™„ë£Œ! (Retrieved: {len(result.get('retrieved_docs', []))}ê±´, News: {len(result.get('news_items', []))}ê±´)")

                params = {
                    "company_name": company_name,
                    "corp_code": corp_code,
                    "question": question,
                    "years": years,
                    "reprt_codes": reprt_codes,
                    "fs_div": fs_div,
                    "news_sort": news_sort,
                    "news_limit": news_limit,
                    "dedup_strength": dedup_strength,
                    "sort_label": sort_label,
                    "dedup_label": dedup_label,
                    "briefing_year": briefing_year,
                    "briefing_year_mode": briefing_year_mode,
                }

                _persist_analysis(params, result)
                
            except Exception as e:
                st.error(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                st.exception(e)

    # ë¶„ì„ ìƒíƒœê°€ ìˆìœ¼ë©´ í•­ìƒ íƒ­ì„ ë Œë”ë§ (ì±— ì…ë ¥ ì‹œì—ë„ ì‚¬ë¼ì§€ì§€ ì•Šë„ë¡)
    analysis = st.session_state.get("analysis")
    if analysis:
        _render_tabs(analysis)
    else:
        st.info("ë¶„ì„ì„ ì‹¤í–‰í•˜ë©´ ê²°ê³¼ íƒ­ì´ í‘œì‹œë©ë‹ˆë‹¤.")


if __name__ == "__main__":
    main()
